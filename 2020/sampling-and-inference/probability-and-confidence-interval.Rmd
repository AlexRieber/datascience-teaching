---
title: "Wahrscheinlichkeiten und Verteilungen"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["../uni-ulm.css", "../uni-ulm-fonts.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
    includes:
      in_header: ../header.html 
#xaringan::inf_mr() #[Start Preview -> Type into console]

---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300,
  fig.align = "center", out.width = "70%", cache = FALSE)
library(tidyverse)
library(knitr)
library(emo)
library(extrafont)
library(png) 
library(xaringan)
library(gridExtra)
library(ggthemes)
library(pander)

ggplot2::theme_set(theme_minimal())
# update those defaults
update_font_defaults <- function(font_choice = "Lato") {
    ggplot2::update_geom_defaults("text", list(family = font_choice))
    ggplot2::update_geom_defaults("label", list(family = font_choice))
    
}
theme_bakeoff <- function(font_choice = "Lato"){ 
  
  update_font_defaults()
  
  ggplot2::theme_minimal(base_family = font_choice)
  
}
ggplot2::theme_set(theme_bakeoff())

gif_link <- function(link, file, size){
    knitr::asis_output(
      paste0('<center>\n<a href="',
             link,
             '">\n<img src="',
             file,
             '" style = "width: ',
             size,
             'px;"/>\n</a>\n</center>'
      ))
}
```

## Wahrscheinlichkeit

.question[Was sind Wahrscheinlichkeiten?]

--

Wenn Sie ein Experiement unabhängig voneinander und unter den selben Bedingungen sehr oft wiederholen können Sie bestimmen mit welchem Anteil ein bestimmtes Ereignis eintritt. Hier sprichen wir von der Wahrscheinlichkeit das dieses Ereignis eintritt.




---

## Monte Carlo Simulation

.question[Können Sie am Computer Experiemnte simulieren um aus diesen Wahrscheinlichkeiten für ein Ereignis zu berechnen?]

Durch Monte Carlo Simulationen können Sie am Computer bestimmte Aktionen beliebig oft durchspielen
  - Theoretisch optimal wäre es das Experiment unendlich oft zu wiederholen
  - Praktisch sollte es so oft wiederholt werden, dass eine weitere Wiederholung das Ergebnis nur noch unwesentlich verändert -> Ergebnis konvergiert zum _wahren_ Wert
  - Statistisch gesehen nähern Sie sich der tatsächlichen Wahrscheinlichkeit mit steigendem $N$ an

--

Bei einer Simulation sollten Sie _immer_ einen sogenannten "seed" setzen!

- Generierung von Zufallszahlen **allerdings** werden durch den "seed" immer die gleichen Zufallszahlen generiert

---

## Grundbegriffe

- **Grundgesamtheit**: Alle Individuen oder Beobachtungen die für uns interessant sind. Die Grundgesamtheit wird oft mit _N_ abgekürzt. Im vorherigen Urnenbeispiel wäre _N_ = 2400.
- **Parameter in der Grundgesamtheit**: Parameter welchen wir gerne kennen würden, jedoch nicht kennen. Bspw. den _Mittelwert der Grundgesamtheit_, welchen wir mathematisch als $\mu$ deklarieren. Oder in unserem Beispiel den Anteil roter Kugeln ( _Anteil der Grundgesamtheit_ ), welches mathematisch $p$ wäre.
- **Zensus**: Eine Zählung aller Individuen in unserer Grundgesamtheit
- **Stichprobe**: Untersuchung nur einer bestimmten Anzahl _n_ von Individuen der Grundgesamtheit. In unserem Beispiel war $n \epsilon [25,50,100]$
- **Punktschätzer**: Geschätzter Parameter auf Basis einer Stichprobe _n_. Mit dem Punktschätzer soll der unbekannte Parameter der Grundgesamtheit geschätzt werden. In unserem Beispiel der Anteil an roten Kugeln. Den Punktschätzer den wir hier erhalten würde mathematisch als $\hat{p}$ definiert anzuzeigen, dass er auf Basis einer Stichprobe geschätzt wurde.
- **Repräsentative Stichprobe**: Eine Stichprobe ist repräsentativ, wenn diese der Grundgesamtheit sehr ähnlich sieht, d.h. wenn deren Charakteristika derer der Grundgesamtheit entsprechen

---

## Grundbegriffe

- **Verallgemeinerbar**: Eine Stichprobe ist verallgemeinerbar, wenn Resultate aus der Stichprobe auch auf die Grundgesamtheit zutreffen. Ist $\hat{p}$ eine gute Abschätzung für $p$?
- **Stichprobenverzerrung**: Entsteht, wenn einige Individuen oder Beobachtungen in der Gesamtpopulation eine höhere Wahrscheinlichkeit haben in der Stichprobe repräsentiert zu sein. Eine Stichprobe ist _unverzerrt_ wenn alle Individuen die gleiche Chance haben in die Stichprobe aufgenommen zu werden
- **Zufällige Stichprobe**: Wenn zufällig und nicht verzerrt aus der Grundgesamtheit gezogen wird

---

## Grundbegriffe

Wenn ihre Stichprobe mit der Größe _n_ zufällig gezogen wird, dann ist ihre Stichprobe

- _unverzerrt_ und _repräsentativ_ für ihre Grundgesamtheit _N_
- alle Resultate aus der Stichprobe sind _verallgemeinerbar_ für die Grundgesamtheit
- die _Punktschätzer_ sind eine gute Abschätzung des Parameters der Population

Somit müssen Sie keinen Zensus durchführen um Aussagen über die Grundgesamtheit machen zu können.



---

## Eine Stichprobe

Was, wenn Sie nur eine Stichprobe haben?

```{r}
set.seed(123)
urne <- as.tibble(rep( c("rot", "weiß"), times = c(760,1240)))
urne <- urne %>% mutate(id = rownames(urne))
colnames(urne) <- c("farbe", "id")

stichprobe <- sample_n(urne, 50)

stichprobe %>% count(farbe)
```

--

Können Sie hiermit etwas über die Stichprobenvarianz (Verteilung mehrerer Stichproben) aussagen?

---

## Stichprobenvarianz

```{r}
library(infer)
stichprobe %>% 
  specify(formula = farbe ~ NULL, success = "rot")
```

---

## Stichprobenvarianz

```{r}
bootstrap <- stichprobe %>% 
  specify(formula = farbe ~ NULL, success = "rot") %>% 
  generate(reps = 48, type = "bootstrap")

bootstrap
```

--

- **farbe** = welche Farbe der Ball hat
- **replicate** = aus welchem Zug der Ball stammt (insgesamt 48 Züge)

---

## Bootstrap

**Ausgangslage:**
- Eine Stichprobe von 20 roten und 30 weiße Kugeln
- Was Sie gerne hätten wäre die Grundgesamtheit:

--

```{r, echo=FALSE}
include_graphics("../figs/sampling_bowl_2.jpg")
```

.small[Quelle: https://moderndive.com/7-sampling.html]

---

## Bootstrap

Können Sie diese Grundgesamtheit durch häufiges Ziehen mit Zurücklegen aus ihrer Stichprobe replizieren?
Dieses ziehen mit Zurücklegen wird hier _bootstrap_ genannt.

--

Bootstrap bedeutet frei übersetzt "sich selbst an seinem Schopf aus dem Sumpf ziehen", was soviel heißt wie "auf Grund seiner eigenen Fähigkeiten Erfolg haben".

- Statistisch gesehen meint dies die Effekte der Stichprobenvarianz nur auf der Basis einer einzelnen Stichprobe herauszufinden
- Besser: Sie können mit dem Bootstrap approximativ eine Stichprobenverteilung konstruieren, nur auf Basis einer einzelnen Stichprobe

---

## Bootstrap Verteilung

```{r}
bootstrap1 <- stichprobe %>% 
  specify(formula = farbe ~ NULL, success = "rot") %>% 
  generate(reps = 48, type = "bootstrap") %>% 
  calculate(stat = "prop")
```
.question[Können Sie aus ihren Daten ein Gefühl für die Stichprobenvarianz in der Gesamtpopulation erhalten?]

--

```{r, echo=FALSE, fig.height=5}
bootstrap1 %>%
  ggplot(aes(x = stat)) +
  geom_histogram(binwidth = 0.02, farbe = "rot") +
  xlim(0.10, 0.60) +
  geom_vline(xintercept = mean(bootstrap1$stat), color = "red",
             size = 1) +
  geom_vline(xintercept = c(mean(bootstrap1$stat) - sd(bootstrap1$stat), mean(bootstrap1$stat) + sd(bootstrap1$stat)), color = "red", size = 1) +
  ggtitle("Der Bootstrap mit 48 Zügen")
```


---

## Bootstrap Verteilung (mit 10 000 Ziehungen)

.question[Wie sieht es aus, wenn Sie die Anzahl der Ziehungen erhöhen?]

--

```{r}
bootstrap2 <- stichprobe %>% 
  specify(formula = farbe ~ NULL, success = "rot") %>% 
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "prop")
```


```{r, echo=FALSE, fig.height=5}
bootstrap2 %>%
  ggplot(aes(x = stat)) +
  geom_histogram(binwidth = 0.02, farbe = "rot") +
  xlim(0.10, 0.60) +
  geom_vline(xintercept = mean(bootstrap2$stat), color = "red",
             size = 1) +
  geom_vline(xintercept = c(mean(bootstrap2$stat) - sd(bootstrap2$stat), mean(bootstrap2$stat) + sd(bootstrap2$stat)), color = "red", size = 1) +
  ggtitle("Der Bootstrap mit 10 000 Zügen")
```



---

## Verteilungen

```{r, echo=FALSE}
g1 <- bootstrap2 %>%
  ggplot(aes(x = stat)) +
  geom_histogram(binwidth = 0.02, farbe = "rot") +
  xlim(0.10, 0.60) +
  geom_vline(xintercept = mean(bootstrap2$stat), color = "red",
             size = 1) +
  geom_vline(xintercept = c(mean(bootstrap2$stat) - sd(bootstrap2$stat), mean(bootstrap2$stat) + sd(bootstrap2$stat)), color = "red", size = 1) +
  ggtitle("Der Bootstrap mit 10 000 Zügen")

urne_anteil10000 <- urne %>%
  rep_sample_n(size=50, reps = 10000) %>%
  group_by(replicate) %>% 
  summarize(anteil_rot = mean(farbe == "rot"))

g2 <- urne_anteil10000 %>%
  ggplot(aes(x = anteil_rot)) +
  geom_histogram(binwidth = 0.02, farbe = "rot") +
  xlim(0.10, 0.60) +
  geom_vline(xintercept = mean(urne_anteil10000$anteil_rot), color = "red",
             size = 1) +
  geom_vline(xintercept = c(mean(urne_anteil10000$anteil_rot) - sd(urne_anteil10000$anteil_rot), mean(urne_anteil10000$anteil_rot) + sd(urne_anteil10000$anteil_rot)), color = "red", size = 1) +
  ggtitle("Die Stichprobenverteilung mit 10 000 Zügen")


library(gridExtra)
grid.arrange(g1,g2, nrow=2)
```


---

## Verteilungen

**Bootstrap Verteilung:**

- Die Bootstrap Verteilung hat nicht den gleichen Mittelwert wie unsere Stichprobenverteilung. D.h. Sie können durch den Bootstrap die Qualität ihres Punktschätzers nicht verbessern
- **Jedoch:** Die Bootstrap Verteilung hat eine sehr ähnliche Form und Schwankungsbreite wie die Stichprobenverteilung. D.h. Bootstrapping kann dazu genutzt werden eine sehr genaue Abschätzung des Standardfehlers zu erhalten

$\rightarrow$ Sie können die Bootstrap Verteilung nutzen um Konfidenzintervalle zu berechnen

---

## Unabhängigkeit

Im vorherigen Urnen-Beispiel hatten wir unabhängige Ereignisse beschrieben. In diesem Fall war das Ziehen von mehreren Kugeln voneinander _unabhängig_, da der erste Zug den zweiten _nicht beeinflusst_ (ziehen mit zurücklegen).

---

## Konfidenzintervalle mit dem `infer` Paket

```{r, echo=FALSE}
include_graphics("../figs/confidence_interval.jpeg")
```

.small[Quelle: Bild von https://moderndive.com/index.html]

---

## Konfidenzintervalle

- **Punktschätzer**: Genauer Wert aus einer Schätzung auf Basis der Stichprobe
- **Konfidenzintervall**: Bandbreite plausibler Werte auf Basis der Stichprobe


**Konfidenzintervalle** werden in der empirischen Forschung sehr häufig verwendent um die **Schätzunsicherheit** anzugeben. Dies gilt nicht nur für die Wirtschaftswissenschaften, sondern alle Bereiche der empirischen Forschung.

---

## Konfidenzintervalle mittels Bootstrap

Eine Möglichkeit besteht darin die Bootstrap Stichprobe heranzuziehen und auf deren Basis die Konfidenzintervalle zu bilden:

```{r, fig.height=4}
conf <- stichprobe %>% 
  specify(response = farbe, success = "rot") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop") 

visualize(conf)
```

---

## Konfidenzintervalle mittels Bootstrap

Was sind die einzelnen Schritte im `infer` Paket?

Definition, welche Variablen im Fokus stehen für die Analyse über `specify()`:

--

```{r, eval=FALSE, fig.height=4}
conf <- stichprobe %>% 
  specify(response = farbe, success = "rot") %>% #<<
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop") 

visualize(conf)
```

---

## Konfidenzintervalle mittels Bootstrap

Was sind die einzelnen Schritte im `infer` Paket?

Anschließend erzeugen Sie mehrere Stichproben über `generate()` (hier mit Bootstrap):

--

```{r, eval=FALSE, fig.height=4}
conf <- stichprobe %>% 
  specify(response = farbe, success = "rot") %>% 
  generate(reps = 1000, type = "bootstrap") %>% #<<
  calculate(stat = "prop") 

visualize(conf)
```

---

## Konfidenzintervalle mittels Bootstrap

Was sind die einzelnen Schritte im `infer` Paket?

Danach sollten Sie definieren, was Sie berechnen wollen mittels `calculate()`:
    - Beispiele: mean, median, sum, sd, prop
--

```{r, eval=FALSE, fig.height=4}
conf <- stichprobe %>% 
  specify(response = farbe, success = "rot") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop") #<<

visualize(conf)
```


---

## Konfidenzintervalle mittels Bootstrap

Was sind die einzelnen Schritte im `infer` Paket?

Schlussendlich können Sie die entstandene Verteilung visualisieren mit `visualize()`:

--

```{r, eval=FALSE, fig.height=4}
conf <- stichprobe %>% 
  specify(response = farbe, success = "rot") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop") 

visualize(conf) #<<
```


---

## Konfidenzintervalle mittels Bootstrap

Konfidenzintervalle in der Verteilung einzeichen:

```{r, fig.height=5}
percentile_ci <- conf %>% 
  get_confidence_interval(level = 0.95, type = "percentile")

visualize(conf) + shade_confidence_interval(endpoints = percentile_ci)
```


---

## Konfidenzintervalle auf Basis der Normalverteilung

.alert[Eine weitere Möglichkeit Konfidenzintervalle zu berechnen ist auf Basis einer Verteilungsannahme.]

In der Regel wird die Normalverteilungsannahme getroffen.
- Die Normalverteilung ist ein sehr wichtiges Konzept in der Mathematik
- Viele Verteilungen sind approximativ normal verteilt
  - Hierunter zählen: Körpergröße, Gewicht, Blutdruck, IQ-Werte, ...

In dieser Veranstaltung konzentrieren wir uns nicht darauf, warum dies so ist, sondern wie Sie die Normalverteilung nützen können

---

## Konfidenzintervalle auf Basis der Normalverteilung

Die mathematische Definition der Normalverteilung besagt, dass der Anteil im Interval $(a,b)$ durch folgende Formel berechnet werden kann:

$$\mbox{Pr}(a < x < b) = \int_a^b \frac{1}{\sqrt{2\pi}\sigma} \exp\left\{-\frac{1}{2}\left( \frac{x-\mu}{\sigma} \right)^2\right\} \, dx$$

Damit ist die Normalverteilung durch zwei Parameter definiert ($\mu$ und $\sigma$)
Hier ist $\mu$ der Mittelwert und $\sigma$ die Standardabweichung der Verteilung.

Die Normalverteilung ist 

  - symmetrisch
  - zentriert um den Mittelwert 
  - 95% aller Werte liegen innerhalb von 2 Standardabweichungen vom Mittelwert

---

## Konfidenzintervalle auf Basis der Normalverteilung

Wenn unser Datensatz nun durch die Normalverteilung approximiert werden kann, so bedeutet dies, dass wir auch unseren Datensatz mit Hilfe von Mittelwert und Standardabweichung darstellen können.

Wie wir bereits wissen ist der Mittelwert definiert als:

$$\mu = \frac{1}{N} \sum_{i=1}^{N} x_{i}$$

und die Standardabweichung kann definiert werden als
$$\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_{i} - \mu)²}$$

- Interpretation der Standardabweichung: Durchschnittliche Abweichung zwischen den Werten der Verteilung und deren Mittelwert

---

## Konfidenzintervalle auf Basis der Normalverteilung

Wenn wir dieses Wissen auf unsere Stichprobe anwenden, dann können wir die Konfidenzintervalle entsprechend einzeichen:

```{r, fig.height=5}
standard_error_ci <- conf %>%
  get_confidence_interval(type = "se", point_estimate = 0.38)

visualize(conf) + shade_confidence_interval(endpoints = standard_error_ci)
```



---

## Konfidenzintervalle

Bei einem 95% Konfidenzintervall:
  - Zu 95% liegt der wahre Wert von $x$ in unserem Intervall
  - Das 95% Konfidenzintervall beinhaltet alle Werte, welche bis zu 2 Standardfehler von unserem geschätzten Mittelwert abweichen $[(\mu - 2\sigma), (\mu + 2\sigma)]$
  - Die Intervallgrenzen sind Zufallsvariablen! 

**Frage:** Wird das Konfidenzintervall größer oder kleiner bei einem Konfidenzniveau von 99%?

---


## Konfidenzintervalle

Um die Wahrscheinlichkeit zu bestimmen, dass $x$ im Intervall liegt berechnen wir folgendes:
$$
\mbox{Pr}\left(\mu -2\sigma \leq x \leq \mu + 2 \sigma)\right)
$$

Dies lässt sich zu folgender Formel umschreiben:

$$
\mbox{Pr}\left(-2 \leq \frac{x - \mu}\sigma \leq  2\right)
$$

---

## Konfidenzintervalle

Der mittlere Term ist hierbei approximativ normalverteilt mit einem Erwartungswert von 0 und einem Standardfehler von 1.
Nennen wir diese Zufallsvariable $Z$:

$$
\mbox{Pr}\left(-2 \leq Z \leq  2\right)
$$

Das heißt, wenn unser Konfidenzintervall 2 Standardfehler vom geschätzten Mittelwert umfasst, so beinhaltet unser Konfidenzintervall mit 95%-iger Wahrscheinlichkeit den wahren Wert $x$.

```{r}
pnorm(2) - pnorm(-2)
```

---

## Konfidenzintervalle

Für ein Konfidenzintervall von genau 95% reicht es einen etwas kleineren Bereich als $2\sigma$ anzuschauen:

```{r}
qnorm(0.975)
```

---

## Die korrekte Beschreibung

Bitte beachten Sie folgendes:

- Das Intervall welches Sie sich oben anschauen unterliegt zufälligen Schwankungen, nicht $x$.
- Es ist falsch zu sagen, dass $x$ eine 95%-ige Wahrscheinlichkeit hat innerhalb des Intervalls zu liegen
- Die 95% beziehen sich auf die Wahrscheinlichkeit, dass dieses zufällige Konfidenzintervall auf $x$ fällt, d.h. $x$ beinhaltet
- Das Intervall schwankt um $x$ nicht umgekehrt

---

## Das 95% Konfidenzintervall

```{r, echo=FALSE, fig.height=6}
p_red <- urne %>% 
  summarize(anteil_rot = mean(farbe == "rot")) %>% 
  pull(anteil_rot)

# Schaubild von hier: https://github.com/moderndive/ModernDive_book/blob/master/08-confidence-intervals.Rmd
if(!file.exists("data/balls_percentile_cis.rds")){
  set.seed(4)
  # Function to run infer pipeline
  bootstrap_pipeline <- function(sample_data){
    sample_data %>% 
      specify(formula = farbe ~ NULL, success = "rot") %>% 
      generate(reps = 1000, type = "bootstrap") %>% 
      calculate(stat = "prop")
  }
  
  # Compute nested data frame with sampled data, sample proportions, all 
  # bootstrap replicates, and percentile_ci
  balls_percentile_cis <- urne %>% 
    rep_sample_n(size = 50, reps = 100, replace = FALSE) %>% 
    group_by(replicate) %>% 
    nest() %>% 
    mutate(sample_prop = map_dbl(data, ~mean(.x$farbe == "rot"))) %>%
    # run infer pipeline on each nested tibble to generated bootstrap replicates
    mutate(bootstraps = map(data, bootstrap_pipeline)) %>% 
    group_by(replicate) %>% 
    # Compute 95% percentile CI's for each nested element
    mutate(percentile_ci = map(bootstraps, get_ci, type = "percentile", level = 0.95))
  
  # Save output to rds object
  saveRDS(object = balls_percentile_cis, "data/balls_percentile_cis.rds")
} else {
  balls_percentile_cis <- readRDS("data/balls_percentile_cis.rds")
}
# Identify if confidence interval captured true p
percentile_cis <- balls_percentile_cis %>% 
  unnest(percentile_ci) %>% 
  mutate(captured = `2.5%` <= p_red & p_red <= `97.5%`)
    
# Plot them!
ggplot(percentile_cis) +
  geom_segment(aes(
    y = replicate, yend = replicate, x = `2.5%`, xend = `97.5%`, 
    alpha = factor(captured, levels = c("TRUE", "FALSE"))
  )) +
  # Removed point estimates since it doesn't necessarily act as center for 
  # percentile-based CI's
  # geom_point(aes(x = sample_prop, y = replicate, color = captured)) +
  labs(x = expression("Anteil an roten Kugeln"), 
       y = "Nummer Zuges", 
       alpha = "Im Konfidenzintervall") +
  geom_vline(xintercept = p_red, color = "red") + 
  coord_cartesian(xlim = c(0.1, 0.7)) + 
  theme_light() + 
  theme(panel.grid.major.y = element_blank(), 
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank())
```

.tiny[Grafik in Anlehnung an die Visualisierung aus Kapitel 8.5: Ismay, C., & Kim, A. Y. (2019). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse.]

---

## Wie gut ist das Konfidenzintervall

```{r,  fig.height=5}
conf %>% 
  visualize(bins = 15) + 
  shade_confidence_interval(endpoints = percentile_ci) +
  geom_vline(xintercept = 0.38, linetype = "dashed")
```

.alert[Unser Punktschätzer liegt im 95%igen Konfidenzintervall.]
---

## Power

Wenn ein Konfidenzintervall die Null beinhaltet, so können wir die Nullhypothese das kein Effekt vorhanden ist _nicht_ ablehnen.

Dies kann jedoch auf verschiedenen Eigenschaften der Stichprobe zurückzuführen sein:

- große Standardabweichung 
- großes Konfidenzintervall, d.h. es wurde ein zu hohes Signifikanzniveau ausgewählt 
- zu kleine Stichprobe. Durch eine größere Stichprobe wird der Standardfehler des Koeffizienten kleiner: $\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$

